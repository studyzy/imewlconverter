---
description: Generate a custom checklist for the current feature based on user requirements.
---

## æ¸…å•ç›®çš„ï¼š"éœ€æ±‚ç¼–å†™çš„å•å…ƒæµ‹è¯•"

**æ ¸å¿ƒæ¦‚å¿µ**ï¼šæ¸…å•æ˜¯**éœ€æ±‚ç¼–å†™çš„å•å…ƒæµ‹è¯•** - å®ƒä»¬éªŒè¯ç‰¹å®šé¢†åŸŸä¸­éœ€æ±‚çš„è´¨é‡ã€æ¸…æ™°åº¦å’Œå®Œæ•´æ€§ã€‚

**ä¸ç”¨äºéªŒè¯/æµ‹è¯•**ï¼š
- âŒ ä¸æ˜¯"éªŒè¯æŒ‰é’®ç‚¹å‡»æ­£ç¡®"
- âŒ ä¸æ˜¯"æµ‹è¯•é”™è¯¯å¤„ç†æœ‰æ•ˆ"
- âŒ ä¸æ˜¯"ç¡®è®¤ API è¿”å› 200"
- âŒ ä¸æ˜¯æ£€æŸ¥ä»£ç /å®ç°æ˜¯å¦ç¬¦åˆè§„èŒƒ

**ç”¨äºéœ€æ±‚è´¨é‡éªŒè¯**ï¼š
- âœ… "æ˜¯å¦ä¸ºæ‰€æœ‰å¡ç‰‡ç±»å‹å®šä¹‰äº†è§†è§‰å±‚æ¬¡éœ€æ±‚ï¼Ÿ"ï¼ˆå®Œæ•´æ€§ï¼‰
- âœ… "'çªå‡ºæ˜¾ç¤º'æ˜¯å¦é€šè¿‡å…·ä½“å°ºå¯¸/ä½ç½®è¿›è¡Œäº†é‡åŒ–ï¼Ÿ"ï¼ˆæ¸…æ™°åº¦ï¼‰
- âœ… "æ‰€æœ‰äº¤äº’å…ƒç´ çš„æ‚¬åœçŠ¶æ€éœ€æ±‚æ˜¯å¦ä¸€è‡´ï¼Ÿ"ï¼ˆä¸€è‡´æ€§ï¼‰
- âœ… "æ˜¯å¦ä¸ºé”®ç›˜å¯¼èˆªå®šä¹‰äº†å¯è®¿é—®æ€§éœ€æ±‚ï¼Ÿ"ï¼ˆè¦†ç›–åº¦ï¼‰
- âœ… "è§„èŒƒæ˜¯å¦å®šä¹‰äº† logo å›¾åƒåŠ è½½å¤±è´¥æ—¶çš„å¤„ç†ï¼Ÿ"ï¼ˆè¾¹ç¼˜æƒ…å†µï¼‰

**æ¯”å–»**ï¼šå¦‚æœä½ çš„è§„èŒƒæ˜¯ç”¨è‹±æ–‡ç¼–å†™çš„ä»£ç ï¼Œé‚£ä¹ˆæ¸…å•å°±æ˜¯å®ƒçš„å•å…ƒæµ‹è¯•å¥—ä»¶ã€‚ä½ æµ‹è¯•çš„æ˜¯éœ€æ±‚æ˜¯å¦ç¼–å†™è‰¯å¥½ã€å®Œæ•´ã€æ˜ç¡®å¹¶å‡†å¤‡å¥½å®æ–½ - è€Œä¸æ˜¯å®ç°æ˜¯å¦æœ‰æ•ˆã€‚

## ç”¨æˆ·è¾“å…¥

```text
$ARGUMENTS
```

åœ¨ç»§ç»­ä¹‹å‰ï¼Œä½ **å¿…é¡»**è€ƒè™‘ç”¨æˆ·è¾“å…¥ï¼ˆå¦‚æœä¸ä¸ºç©ºï¼‰ã€‚

## æ‰§è¡Œæ­¥éª¤

1. **è®¾ç½®**ï¼šä»ä»“åº“æ ¹ç›®å½•è¿è¡Œ `.specify/scripts/bash/check-prerequisites.sh --json` å¹¶è§£æJSONä»¥è·å–FEATURE_DIRå’ŒAVAILABLE_DOCSåˆ—è¡¨ã€‚
   - æ‰€æœ‰æ–‡ä»¶è·¯å¾„å¿…é¡»æ˜¯ç»å¯¹è·¯å¾„ã€‚
   - å¯¹äºå‚æ•°ä¸­çš„å•å¼•å·å¦‚"I'm Groot"ï¼Œä½¿ç”¨è½¬ä¹‰è¯­æ³•ï¼šä¾‹å¦‚ 'I'\''m Groot'ï¼ˆæˆ–è€…å°½å¯èƒ½ä½¿ç”¨åŒå¼•å·ï¼š"I'm Groot"ï¼‰ã€‚

2. **æ¾„æ¸…æ„å›¾ï¼ˆåŠ¨æ€ï¼‰**ï¼šæ¨å¯¼æœ€å¤šä¸‰ä¸ªåˆå§‹ä¸Šä¸‹æ–‡æ¾„æ¸…é—®é¢˜ï¼ˆæ— é¢„ç¼–ç›®å½•ï¼‰ã€‚å®ƒä»¬å¿…é¡»ï¼š
   - ä»ç”¨æˆ·çš„è¡¨è¿° + ä»è§„èŒƒ/è®¡åˆ’/ä»»åŠ¡ä¸­æå–çš„ä¿¡å·ç”Ÿæˆ
   - åªè¯¢é—®å®è´¨ä¸Šæ”¹å˜æ¸…å•å†…å®¹çš„ä¿¡æ¯
   - å¦‚æœåœ¨`$ARGUMENTS`ä¸­å·²ç»æ˜ç¡®ï¼Œåˆ™å•ç‹¬è·³è¿‡
   - ä¼˜å…ˆè€ƒè™‘ç²¾ç¡®æ€§è€Œéå¹¿åº¦

   Generation algorithm:
   1. Extract signals: feature domain keywords (e.g., auth, latency, UX, API), risk indicators ("critical", "must", "compliance"), stakeholder hints ("QA", "review", "security team"), and explicit deliverables ("a11y", "rollback", "contracts").
   2. Cluster signals into candidate focus areas (max 4) ranked by relevance.
   3. Identify probable audience & timing (author, reviewer, QA, release) if not explicit.
   4. Detect missing dimensions: scope breadth, depth/rigor, risk emphasis, exclusion boundaries, measurable acceptance criteria.
   5. Formulate questions chosen from these archetypes:
      - Scope refinement (e.g., "Should this include integration touchpoints with X and Y or stay limited to local module correctness?")
      - Risk prioritization (e.g., "Which of these potential risk areas should receive mandatory gating checks?")
      - Depth calibration (e.g., "Is this a lightweight pre-commit sanity list or a formal release gate?")
      - Audience framing (e.g., "Will this be used by the author only or peers during PR review?")
      - Boundary exclusion (e.g., "Should we explicitly exclude performance tuning items this round?")
      - Scenario class gap (e.g., "No recovery flows detectedâ€”are rollback / partial failure paths in scope?")

   Question formatting rules:
   - If presenting options, generate a compact table with columns: Option | Candidate | Why It Matters
   - Limit to Aâ€“E options maximum; omit table if a free-form answer is clearer
   - Never ask the user to restate what they already said
   - Avoid speculative categories (no hallucination). If uncertain, ask explicitly: "Confirm whether X belongs in scope."

   Defaults when interaction impossible:
   - Depth: Standard
   - Audience: Reviewer (PR) if code-related; Author otherwise
   - Focus: Top 2 relevance clusters

   Output the questions (label Q1/Q2/Q3). After answers: if â‰¥2 scenario classes (Alternate / Exception / Recovery / Non-Functional domain) remain unclear, you MAY ask up to TWO more targeted followâ€‘ups (Q4/Q5) with a one-line justification each (e.g., "Unresolved recovery path risk"). Do not exceed five total questions. Skip escalation if user explicitly declines more.

3. **ç†è§£ç”¨æˆ·è¯·æ±‚**ï¼šç»“åˆ `$ARGUMENTS` + æ¾„æ¸…ç­”æ¡ˆï¼š
   - æ¨å¯¼æ¸…å•ä¸»é¢˜ï¼ˆä¾‹å¦‚ï¼šsecurity, review, deploy, uxï¼‰
   - æ•´åˆç”¨æˆ·æ˜ç¡®æåˆ°çš„å¿…éœ€é¡¹ç›®
   - å°†ç„¦ç‚¹é€‰æ‹©æ˜ å°„åˆ°ç±»åˆ«æ¡†æ¶
   - ä»è§„èŒƒ/è®¡åˆ’/ä»»åŠ¡ä¸­æ¨æ–­ä»»ä½•ç¼ºå¤±çš„ä¸Šä¸‹æ–‡ï¼ˆä¸è¦è™šæ„ï¼‰

4. **åŠ è½½åŠŸèƒ½ä¸Šä¸‹æ–‡**ï¼šä» FEATURE_DIR è¯»å–ï¼š
   - spec.mdï¼šåŠŸèƒ½éœ€æ±‚å’ŒèŒƒå›´
   - plan.mdï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼šæŠ€æœ¯ç»†èŠ‚ã€ä¾èµ–å…³ç³»
   - tasks.mdï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼šå®æ–½ä»»åŠ¡

   **ä¸Šä¸‹æ–‡åŠ è½½ç­–ç•¥**ï¼š
   - ä»…åŠ è½½ä¸æ´»åŠ¨ç„¦ç‚¹åŒºåŸŸç›¸å…³çš„å¿…è¦éƒ¨åˆ†ï¼ˆé¿å…å…¨æ–‡è½¬å‚¨ï¼‰
   - ä¼˜å…ˆå°†é•¿éƒ¨åˆ†æ€»ç»“ä¸ºç®€æ´çš„åœºæ™¯/éœ€æ±‚è¦ç‚¹
   - ä½¿ç”¨æ¸è¿›å¼æŠ«éœ²ï¼šä»…åœ¨æ£€æµ‹åˆ°å·®è·æ—¶æ·»åŠ åç»­æ£€ç´¢
   - å¦‚æœæºæ–‡æ¡£å¾ˆå¤§ï¼Œç”Ÿæˆä¸´æ—¶æ‘˜è¦é¡¹ç›®è€Œä¸æ˜¯åµŒå…¥åŸå§‹æ–‡æœ¬

5. **ç”Ÿæˆæ¸…å•** - åˆ›å»º"éœ€æ±‚çš„å•å…ƒæµ‹è¯•"ï¼š
   - Create `FEATURE_DIR/checklists/` directory if it doesn't exist
   - Generate unique checklist filename:
     - Use short, descriptive name based on domain (e.g., `ux.md`, `api.md`, `security.md`)
     - Format: `[domain].md` 
     - If file exists, append to existing file
   - Number items sequentially starting from CHK001
   - Each `/speckit.checklist` run creates a NEW file (never overwrites existing checklists)

   **æ ¸å¿ƒåŸåˆ™ - æµ‹è¯•éœ€æ±‚ï¼Œè€Œéå®ç°**ï¼š
   æ¯ä¸ªæ¸…å•é¡¹ç›®å¿…é¡»è¯„ä¼°éœ€æ±‚æœ¬èº«ï¼Œæ£€æŸ¥ï¼š
   - **å®Œæ•´æ€§**ï¼šæ‰€æœ‰å¿…è¦çš„éœ€æ±‚æ˜¯å¦å­˜åœ¨ï¼Ÿ
   - **æ¸…æ™°åº¦**ï¼šéœ€æ±‚æ˜¯å¦æ˜ç¡®æ— æ­§ä¹‰ä¸”å…·ä½“ï¼Ÿ
   - **ä¸€è‡´æ€§**ï¼šéœ€æ±‚ä¹‹é—´æ˜¯å¦ç›¸äº’ä¸€è‡´ï¼Ÿ
   - **å¯æµ‹é‡æ€§**ï¼šéœ€æ±‚æ˜¯å¦å¯ä»¥å®¢è§‚éªŒè¯ï¼Ÿ
   - **è¦†ç›–åº¦**ï¼šæ˜¯å¦æ¶µç›–äº†æ‰€æœ‰åœºæ™¯/è¾¹ç¼˜æƒ…å†µï¼Ÿ

   **ç±»åˆ«ç»“æ„** - æŒ‰éœ€æ±‚è´¨é‡ç»´åº¦åˆ†ç»„é¡¹ç›®ï¼š
   - **éœ€æ±‚å®Œæ•´æ€§**ï¼ˆæ‰€æœ‰å¿…è¦çš„éœ€æ±‚æ˜¯å¦å·²è®°å½•ï¼Ÿï¼‰
   - **éœ€æ±‚æ¸…æ™°åº¦**ï¼ˆéœ€æ±‚æ˜¯å¦å…·ä½“ä¸”æ— æ­§ä¹‰ï¼Ÿï¼‰
   - **éœ€æ±‚ä¸€è‡´æ€§**ï¼ˆéœ€æ±‚æ˜¯å¦ä¸€è‡´ä¸”æ— å†²çªï¼Ÿï¼‰
   - **éªŒæ”¶æ ‡å‡†è´¨é‡**ï¼ˆæˆåŠŸæ ‡å‡†æ˜¯å¦å¯æµ‹é‡ï¼Ÿï¼‰
   - **åœºæ™¯è¦†ç›–åº¦**ï¼ˆæ˜¯å¦æ¶µç›–äº†æ‰€æœ‰æµç¨‹/æƒ…å†µï¼Ÿï¼‰
   - **è¾¹ç¼˜æƒ…å†µè¦†ç›–åº¦**ï¼ˆæ˜¯å¦å®šä¹‰äº†è¾¹ç•Œæ¡ä»¶ï¼Ÿï¼‰
   - **éåŠŸèƒ½æ€§éœ€æ±‚**ï¼ˆæ€§èƒ½ã€å®‰å…¨æ€§ã€å¯è®¿é—®æ€§ç­‰ - æ˜¯å¦å·²æŒ‡å®šï¼Ÿï¼‰
   - **ä¾èµ–å…³ç³»å’Œå‡è®¾**ï¼ˆæ˜¯å¦å·²è®°å½•å’ŒéªŒè¯ï¼Ÿï¼‰
   - **æ­§ä¹‰å’Œå†²çª**ï¼ˆä»€ä¹ˆéœ€è¦æ¾„æ¸…ï¼Ÿï¼‰

   **å¦‚ä½•ç¼–å†™æ¸…å•é¡¹ç›® - "éœ€æ±‚ç¼–å†™çš„å•å…ƒæµ‹è¯•"**ï¼š
   
   âŒ **WRONG** (Testing implementation):
   - "Verify landing page displays 3 episode cards"
   - "Test hover states work on desktop"
   - "Confirm logo click navigates home"
   
   âœ… **CORRECT** (Testing requirements quality):
   - "Are the exact number and layout of featured episodes specified?" [Completeness]
   - "Is 'prominent display' quantified with specific sizing/positioning?" [Clarity]
   - "Are hover state requirements consistent across all interactive elements?" [Consistency]
   - "Are keyboard navigation requirements defined for all interactive UI?" [Coverage]
   - "Is the fallback behavior specified when logo image fails to load?" [Edge Cases]
   - "Are loading states defined for asynchronous episode data?" [Completeness]
   - "Does the spec define visual hierarchy for competing UI elements?" [Clarity]
   
   **é¡¹ç›®ç»“æ„**ï¼š
   Each item should follow this pattern:
   - Question format asking about requirement quality
   - Focus on what's WRITTEN (or not written) in the spec/plan
   - Include quality dimension in brackets [Completeness/Clarity/Consistency/etc.]
   - Reference spec section `[Spec Â§X.Y]` when checking existing requirements
   - Use `[Gap]` marker when checking for missing requirements
   
   **æŒ‰è´¨é‡ç»´åº¦åˆ†ç±»çš„ç¤ºä¾‹**ï¼š
   
   å®Œæ•´æ€§ï¼š
   - "Are error handling requirements defined for all API failure modes? [Gap]"
   - "Are accessibility requirements specified for all interactive elements? [Completeness]"
   - "Are mobile breakpoint requirements defined for responsive layouts? [Gap]"
   
   æ¸…æ™°åº¦ï¼š
   - "Is 'fast loading' quantified with specific timing thresholds? [Clarity, Spec Â§NFR-2]"
   - "Are 'related episodes' selection criteria explicitly defined? [Clarity, Spec Â§FR-5]"
   - "Is 'prominent' defined with measurable visual properties? [Ambiguity, Spec Â§FR-4]"
   
   ä¸€è‡´æ€§ï¼š
   - "Do navigation requirements align across all pages? [Consistency, Spec Â§FR-10]"
   - "Are card component requirements consistent between landing and detail pages? [Consistency]"
   
   è¦†ç›–åº¦ï¼š
   - "Are requirements defined for zero-state scenarios (no episodes)? [Coverage, Edge Case]"
   - "Are concurrent user interaction scenarios addressed? [Coverage, Gap]"
   - "Are requirements specified for partial data loading failures? [Coverage, Exception Flow]"
   
   å¯æµ‹é‡æ€§ï¼š
   - "Are visual hierarchy requirements measurable/testable? [Acceptance Criteria, Spec Â§FR-1]"
   - "Can 'balanced visual weight' be objectively verified? [Measurability, Spec Â§FR-2]"

   **åœºæ™¯åˆ†ç±»ä¸è¦†ç›–åº¦**ï¼ˆéœ€æ±‚è´¨é‡ç„¦ç‚¹ï¼‰ï¼š
   - Check if requirements exist for: Primary, Alternate, Exception/Error, Recovery, Non-Functional scenarios
   - For each scenario class, ask: "Are [scenario type] requirements complete, clear, and consistent?"
   - If scenario class missing: "Are [scenario type] requirements intentionally excluded or missing? [Gap]"
   - Include resilience/rollback when state mutation occurs: "Are rollback requirements defined for migration failures? [Gap]"

   **å¯è¿½æº¯æ€§è¦æ±‚**ï¼š
   - MINIMUM: â‰¥80% of items MUST include at least one traceability reference
   - Each item should reference: spec section `[Spec Â§X.Y]`, or use markers: `[Gap]`, `[Ambiguity]`, `[Conflict]`, `[Assumption]`
   - If no ID system exists: "Is a requirement & acceptance criteria ID scheme established? [Traceability]"

   **å‘ç°å’Œè§£å†³é—®é¢˜**ï¼ˆéœ€æ±‚è´¨é‡é—®é¢˜ï¼‰ï¼š
   Ask questions about the requirements themselves:
   - Ambiguities: "Is the term 'fast' quantified with specific metrics? [Ambiguity, Spec Â§NFR-1]"
   - Conflicts: "Do navigation requirements conflict between Â§FR-10 and Â§FR-10a? [Conflict]"
   - Assumptions: "Is the assumption of 'always available podcast API' validated? [Assumption]"
   - Dependencies: "Are external podcast API requirements documented? [Dependency, Gap]"
   - Missing definitions: "Is 'visual hierarchy' defined with measurable criteria? [Gap]"

   **å†…å®¹æ•´åˆ**ï¼š
   - Soft cap: If raw candidate items > 40, prioritize by risk/impact
   - Merge near-duplicates checking the same requirement aspect
   - If >5 low-impact edge cases, create one item: "Are edge cases X, Y, Z addressed in requirements? [Coverage]"

   **ğŸš« ABSOLUTELY PROHIBITED** - These make it an implementation test, not a requirements test:
   - âŒ Any item starting with "Verify", "Test", "Confirm", "Check" + implementation behavior
   - âŒ References to code execution, user actions, system behavior
   - âŒ "Displays correctly", "works properly", "functions as expected"
   - âŒ "Click", "navigate", "render", "load", "execute"
   - âŒ Test cases, test plans, QA procedures
   - âŒ Implementation details (frameworks, APIs, algorithms)
   
   **âœ… REQUIRED PATTERNS** - These test requirements quality:
   - âœ… "Are [requirement type] defined/specified/documented for [scenario]?"
   - âœ… "Is [vague term] quantified/clarified with specific criteria?"
   - âœ… "Are requirements consistent between [section A] and [section B]?"
   - âœ… "Can [requirement] be objectively measured/verified?"
   - âœ… "Are [edge cases/scenarios] addressed in requirements?"
   - âœ… "Does the spec define [missing aspect]?"

6. **ç»“æ„å‚è€ƒ**ï¼šæŒ‰ç…§ `.specify/templates/checklist-template.md` ä¸­çš„è§„èŒƒæ¨¡æ¿ç”Ÿæˆæ¸…å•ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€å…ƒéƒ¨åˆ†ã€ç±»åˆ«æ ‡é¢˜å’Œ ID æ ¼å¼ã€‚å¦‚æœæ¨¡æ¿ä¸å¯ç”¨ï¼Œä½¿ç”¨ï¼šH1 æ ‡é¢˜ã€purpose/created å…ƒè¡Œã€åŒ…å« `- [ ] CHK### <requirement item>` è¡Œçš„ `##` ç±»åˆ«éƒ¨åˆ†ï¼ŒID ä» CHK001 å¼€å§‹å…¨å±€é€’å¢ã€‚

7. **æŠ¥å‘Š**ï¼šè¾“å‡ºåˆ›å»ºæ¸…å•çš„å®Œæ•´è·¯å¾„ã€é¡¹ç›®æ•°é‡ï¼Œå¹¶æé†’ç”¨æˆ·æ¯æ¬¡è¿è¡Œéƒ½ä¼šåˆ›å»ºæ–°æ–‡ä»¶ã€‚æ€»ç»“ï¼š
   - é€‰æ‹©çš„ç„¦ç‚¹åŒºåŸŸ
   - æ·±åº¦çº§åˆ«
   - æ‰§è¡Œè€…/æ—¶é—´
   - ä»»ä½•æ•´åˆçš„ç”¨æˆ·æ˜ç¡®æŒ‡å®šçš„å¿…éœ€é¡¹ç›®

**é‡è¦è¯´æ˜**ï¼šæ¯æ¬¡ `/speckit.checklist` å‘½ä»¤è°ƒç”¨éƒ½ä¼šåˆ›å»ºä¸€ä¸ªä½¿ç”¨ç®€çŸ­æè¿°æ€§åç§°çš„æ¸…å•æ–‡ä»¶ï¼Œé™¤éæ–‡ä»¶å·²å­˜åœ¨ã€‚è¿™å…è®¸ï¼š

- åˆ›å»ºå¤šç§ä¸åŒç±»å‹çš„æ¸…å•ï¼ˆä¾‹å¦‚ï¼š`ux.md`, `test.md`, `security.md`ï¼‰
- ä½¿ç”¨ç®€å•ã€æ˜“è®°çš„æ–‡ä»¶åæ¥è¡¨æ˜æ¸…å•ç”¨é€”
- åœ¨ `checklists/` æ–‡ä»¶å¤¹ä¸­è½»æ¾è¯†åˆ«å’Œå¯¼èˆª

ä¸ºé¿å…æ··ä¹±ï¼Œè¯·ä½¿ç”¨æè¿°æ€§ç±»å‹ï¼Œå¹¶åœ¨å®Œæˆåæ¸…ç†è¿‡æ—¶çš„æ¸…å•ã€‚

## ç¤ºä¾‹æ¸…å•ç±»å‹å’Œç¤ºä¾‹é¡¹ç›®

**UX éœ€æ±‚è´¨é‡**ï¼š`ux.md`

ç¤ºä¾‹é¡¹ç›®ï¼ˆæµ‹è¯•éœ€æ±‚ï¼Œè€Œéå®ç°ï¼‰ï¼š
- "Are visual hierarchy requirements defined with measurable criteria? [Clarity, Spec Â§FR-1]"
- "Is the number and positioning of UI elements explicitly specified? [Completeness, Spec Â§FR-1]"
- "Are interaction state requirements (hover, focus, active) consistently defined? [Consistency]"
- "Are accessibility requirements specified for all interactive elements? [Coverage, Gap]"
- "Is fallback behavior defined when images fail to load? [Edge Case, Gap]"
- "Can 'prominent display' be objectively measured? [Measurability, Spec Â§FR-4]"

**API éœ€æ±‚è´¨é‡**ï¼š`api.md`

ç¤ºä¾‹é¡¹ç›®ï¼š
- "Are error response formats specified for all failure scenarios? [Completeness]"
- "Are rate limiting requirements quantified with specific thresholds? [Clarity]"
- "Are authentication requirements consistent across all endpoints? [Consistency]"
- "Are retry/timeout requirements defined for external dependencies? [Coverage, Gap]"
- "Is versioning strategy documented in requirements? [Gap]"

**æ€§èƒ½éœ€æ±‚è´¨é‡**ï¼š`performance.md`

ç¤ºä¾‹é¡¹ç›®ï¼š
- "Are performance requirements quantified with specific metrics? [Clarity]"
- "Are performance targets defined for all critical user journeys? [Coverage]"
- "Are performance requirements under different load conditions specified? [Completeness]"
- "Can performance requirements be objectively measured? [Measurability]"
- "Are degradation requirements defined for high-load scenarios? [Edge Case, Gap]"

**å®‰å…¨éœ€æ±‚è´¨é‡**ï¼š`security.md`

ç¤ºä¾‹é¡¹ç›®ï¼š
- "Are authentication requirements specified for all protected resources? [Coverage]"
- "Are data protection requirements defined for sensitive information? [Completeness]"
- "Is the threat model documented and requirements aligned to it? [Traceability]"
- "Are security requirements consistent with compliance obligations? [Consistency]"
- "Are security failure/breach response requirements defined? [Gap, Exception Flow]"

## åä¾‹ï¼šä»€ä¹ˆä¸è¦åš

**âŒ é”™è¯¯ - è¿™äº›æµ‹è¯•å®ç°ï¼Œè€Œééœ€æ±‚ï¼š**

```markdown
- [ ] CHK001 - Verify landing page displays 3 episode cards [Spec Â§FR-001]
- [ ] CHK002 - Test hover states work correctly on desktop [Spec Â§FR-003]
- [ ] CHK003 - Confirm logo click navigates to home page [Spec Â§FR-010]
- [ ] CHK004 - Check that related episodes section shows 3-5 items [Spec Â§FR-005]
```

**âœ… æ­£ç¡® - è¿™äº›æµ‹è¯•éœ€æ±‚è´¨é‡ï¼š**

```markdown
- [ ] CHK001 - Are the number and layout of featured episodes explicitly specified? [Completeness, Spec Â§FR-001]
- [ ] CHK002 - Are hover state requirements consistently defined for all interactive elements? [Consistency, Spec Â§FR-003]
- [ ] CHK003 - Are navigation requirements clear for all clickable brand elements? [Clarity, Spec Â§FR-010]
- [ ] CHK004 - Is the selection criteria for related episodes documented? [Gap, Spec Â§FR-005]
- [ ] CHK005 - Are loading state requirements defined for asynchronous episode data? [Gap]
- [ ] CHK006 - Can "visual hierarchy" requirements be objectively measured? [Measurability, Spec Â§FR-001]
```

**å…³é”®åŒºåˆ«ï¼š**
- é”™è¯¯ï¼šæµ‹è¯•ç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œ
- æ­£ç¡®ï¼šæµ‹è¯•éœ€æ±‚æ˜¯å¦ç¼–å†™æ­£ç¡®
- é”™è¯¯ï¼šéªŒè¯è¡Œä¸º
- æ­£ç¡®ï¼šéªŒè¯éœ€æ±‚è´¨é‡
- é”™è¯¯ï¼š"å®ƒæ˜¯å¦åš Xï¼Ÿ"
- æ­£ç¡®ï¼š"X æ˜¯å¦æ˜ç¡®æŒ‡å®šï¼Ÿ"
